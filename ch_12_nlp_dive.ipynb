{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5jF3xTRs5ZJFylcF8hyoo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshgregory42/practical_deep_learning/blob/main/ch_12_nlp_dive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Language Model from Scratch"
      ],
      "metadata": {
        "id": "i5f1XXBdX2lQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Data\n",
        "\n",
        "Dataset is called *Human Numbers*, which contains the first 10,000 numbers written out in English. This is a dataset that will let us try out methods quickly and easily and interpret the results.\n",
        "\n",
        "Download the dataset the usual way:"
      ],
      "metadata": {
        "id": "C-evlE5JYR1f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "zKtiZKLZXyHe",
        "outputId": "e020c12d-b8dc-49ea-e7ce-5c2c00415c85"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='32768' class='' max='30252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      108.32% [32768/30252 00:00&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from fastai.text.all import *\n",
        "path = untar_data(URLs.HUMAN_NUMBERS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path.ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-pZLUOTYi--",
        "outputId": "906d851f-2e6d-4bcc-a376-063f27d2acde"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('/root/.fastai/data/human_numbers/valid.txt'),Path('/root/.fastai/data/human_numbers/train.txt')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open up those two files and see what's inside. First will join everything together and ignore the train/valid split (will come back to it later):"
      ],
      "metadata": {
        "id": "NWd5PDuQYlJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines = L()\n",
        "with open(path/'train.txt') as f: lines += L(*f.readlines())\n",
        "with open(path/'valid.txt') as f: lines += L(*f.readlines())"
      ],
      "metadata": {
        "id": "spsYXjPKYjjL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take all those lines and concatenate them, separating them with '.':"
      ],
      "metadata": {
        "id": "sWhMMuUKY2k2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' . '.join([l.strip() for l in lines])\n",
        "\n",
        "text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "mz3N6CSUYzqH",
        "outputId": "0eec1b37-eb82-4641-bb54-4cf82c8acb71"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'one . two . three . four . five . six . seven . eight . nine . ten . eleven . twelve . thirteen . fo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize by splitting on spaces:"
      ],
      "metadata": {
        "id": "1sku02EnZAZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text.split(' ')\n",
        "tokens[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXT-iZgjY-3o",
        "outputId": "63accb37-3d48-4644-892a-433634561c45"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one', '.', 'two', '.', 'three', '.', 'four', '.', 'five', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To numericalize, have to create a list of all the unique tokens (our *vocab*):"
      ],
      "metadata": {
        "id": "-eK_39cwZFt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = L(*(tokens)).unique()\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyIztk0uZEFn",
        "outputId": "b38a6d9b-2e3b-4c44-f8ab-b113c71b7092"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#30) ['one','.','two','three','four','five','six','seven','eight','nine'...]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert our tokens into numbers by looking up the index of each in the vocab:"
      ],
      "metadata": {
        "id": "2G008y3pZO3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = {w:i for i, w in enumerate(vocab)}\n",
        "\n",
        "nums = L(word2idx[i] for i in tokens)\n",
        "nums"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COmij2JLZMnm",
        "outputId": "ca7a7ca4-f525-4236-e79c-b0c57eb85ee5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#63095) [0,1,2,1,3,1,4,1,5,1...]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First Lanuage Model from Scratch\n",
        "\n",
        "A simple way to turn this into a neural network would be to specify that we are going to predict each word based on the previous three words. Could create a list of every sequence of three words as our independent variables, and the next word after each sequence as the dependent variable.\n",
        "\n",
        "Can do that with plain Python. First do it with tokens to confirm what it looks like:"
      ],
      "metadata": {
        "id": "B22tKoa2aCsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L((tokens[i:i+3], tokens[i+3]) for i in range(0, len(tokens)-4,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2axHMnl5ZYWE",
        "outputId": "d91f1f16-5c50-4fbf-c524-13e641b9dc68"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(['one', '.', 'two'], '.'),(['.', 'three', '.'], 'four'),(['four', '.', 'five'], '.'),(['.', 'six', '.'], 'seven'),(['seven', '.', 'eight'], '.'),(['.', 'nine', '.'], 'ten'),(['ten', '.', 'eleven'], '.'),(['.', 'twelve', '.'], 'thirteen'),(['thirteen', '.', 'fourteen'], '.'),(['.', 'fifteen', '.'], 'sixteen')...]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now do it with tensors of the numericalized values, which is what the model will actually use:"
      ],
      "metadata": {
        "id": "GQBRxv95alSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seqs = L((tensor(nums[i:i+3]), nums[i+3]) for i in range(0, len(nums)-4, 3))\n",
        "seqs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mShzcbgMaiQv",
        "outputId": "c65c9c5e-778e-44de-ae52-d8e19caa0ac1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(tensor([0, 1, 2]), 1),(tensor([1, 3, 1]), 4),(tensor([4, 1, 5]), 1),(tensor([1, 6, 1]), 7),(tensor([7, 1, 8]), 1),(tensor([1, 9, 1]), 10),(tensor([10,  1, 11]), 1),(tensor([ 1, 12,  1]), 13),(tensor([13,  1, 14]), 1),(tensor([ 1, 15,  1]), 16)...]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can batch those using the `DataLoader` class. For now we'll split the sequences randomly:"
      ],
      "metadata": {
        "id": "qqcqe1lEbhKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 64\n",
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(seqs[:cut], seqs[cut:], bs=64, shuffle=False)"
      ],
      "metadata": {
        "id": "CioptDt1be3S"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we create a neural network architecture that takes three words as input, and returns a prediction of the probability of each possible next word in the vocab. Use three standard layers, with a few changes:\n",
        "\n",
        "First change is that the first linear layer will only use the first word's embedding as activations, the second layer will use the second word's embedding plus the first layer's output activations, and the third layer will use the third word's embedding plus the second layer's output activations. Key effect here is that every word is interpreted in the information context of any words preceding it.\n",
        "\n",
        "Second main change is that each of these three layers will use the same weight matrix. This means that the way one word impacts the activations from previous words should not change depending on the position of the word. So a layer does not learn one sequence position; must learn to handle all positions.\n",
        "\n",
        "Since layer weights don't change, could think of the sequential layers as \"the same layer\" repeated."
      ],
      "metadata": {
        "id": "Glgaepq7cBre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Our Language Model in PyTorch\n",
        "\n",
        "Create the language model module that we described earlier:"
      ],
      "metadata": {
        "id": "y09d22xmfsaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LMModel1(Module):\n",
        "  def __init__(self, vocab_sz, n_hidden):\n",
        "    self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "    self.h_h = nn.Linear(n_hidden, n_hidden)\n",
        "    self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h = F.relu(self.h_h(self.i_h(x[:, 0])))\n",
        "    h = h + self.i_h(x[:, 1])\n",
        "    h = F.relu(self.h_h(h))\n",
        "    h = h + self.i_h(x[:, 2])\n",
        "    h = F.relu(self.h_h(h))\n",
        "    return self.h_o(h)"
      ],
      "metadata": {
        "id": "ezezQ6lkbxii"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've created three layers here:\n",
        "\n",
        "* The embedding layer (`i_h`, for *input* to *hidden*)\n",
        "* The linear layer to create the activations for the next word (`h_h`, for *hidden* to *hidden*)\n",
        "* A final linear layer to predict the fourth word (`h_o`, for *hidden* to *output*)\n",
        "\n"
      ],
      "metadata": {
        "id": "3y3v88dhjLvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try training this model and see what happens:"
      ],
      "metadata": {
        "id": "WE4N8zltjn4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, LMModel1(len(vocab), 64), loss_func=F.cross_entropy,\n",
        "                              metrics=accuracy)\n",
        "\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "iBy24gN-ix4D",
        "outputId": "fe3a7080-8d05-4d22-cf49-29c137260ac1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.791373</td>\n",
              "      <td>1.968191</td>\n",
              "      <td>0.478726</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.407304</td>\n",
              "      <td>1.744796</td>\n",
              "      <td>0.474923</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.402936</td>\n",
              "      <td>1.648738</td>\n",
              "      <td>0.496553</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.372682</td>\n",
              "      <td>1.625802</td>\n",
              "      <td>0.492750</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compare this to what a really simple model would give us. We could always predict the mode common token, so let's find out which token is most often the target in our validation set:"
      ],
      "metadata": {
        "id": "-orVFypbkLL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n, counts = 0, torch.zeros(len(vocab))\n",
        "\n",
        "for x, y in dls.valid:\n",
        "  n += y.shape[0]\n",
        "  for i in range_of(vocab): counts[i] += (y==i).long().sum()\n",
        "\n",
        "idx = torch.argmax(counts)\n",
        "idx, vocab[idx.item()], counts[idx].item()/n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_vy6-cXkS8G",
        "outputId": "d85d2b01-b7f7-4279-9bbf-2b61e0f5e916"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(29), 'thousand', 0.15165200855716662)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most common token has the index of 29, which corresponds to `thousand`. So if we always predicted this token we would have an accuracy of roughly 15\\%, so our model is doing much better.\n",
        "\n",
        "This baseline is okay. Let's see how we can refactor it with a loop."
      ],
      "metadata": {
        "id": "1dAvFwufkm_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Our First Recurrent Neural Network\n",
        "\n",
        "We could simplify our module code by replacing it with code that calls the layers with a `for` loop. This would make our code simpler and also let us apply our module equally well to token sequences of different lengths. Won't be limited to token lists of length three:"
      ],
      "metadata": {
        "id": "hFd0zLIClaYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LMModel2(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = 0\n",
        "        for i in range(3):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = F.relu(self.h_h(h))\n",
        "        return self.h_o(h)"
      ],
      "metadata": {
        "id": "xvCIgQyYklfh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that we get the same results using this refactoring:"
      ],
      "metadata": {
        "id": "gUQgwysqlxGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, LMModel2(len(vocab), 64), loss_func=F.cross_entropy,\n",
        "                metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "z6eQECXtluYx",
        "outputId": "ac67bde0-7057-40ff-e2ed-2440802cee9a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.857394</td>\n",
              "      <td>1.903886</td>\n",
              "      <td>0.458522</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.393145</td>\n",
              "      <td>1.731786</td>\n",
              "      <td>0.466128</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.406300</td>\n",
              "      <td>1.594919</td>\n",
              "      <td>0.491799</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.380854</td>\n",
              "      <td>1.658734</td>\n",
              "      <td>0.410744</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that a neural network that has a loop like this is called a *recurrent neural network* (RNN). An RNN isn't something new, it's just a refactoring of a multilayer neural network using a `for` loop. Could just call it a \"looping neural network\" and it would mean the same thing."
      ],
      "metadata": {
        "id": "UwFKu0IpmlAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving the RNN\n",
        "\n"
      ],
      "metadata": {
        "id": "GbxIr7cjm0dC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Db0uIQ-Il-P5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}